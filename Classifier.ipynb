{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import cv2\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(outputs, labels):\n",
    "    outputs_cpy = copy.copy(outputs)\n",
    "    labels_cpy  = copy.copy(labels)\n",
    "    outputs_cpy = torch.max(outputs_cpy, 1)[1].cpu().detach().numpy()\n",
    "    #print(outputs_cpy)\n",
    "    labels_cpy  = labels_cpy.cpu().detach().numpy()\n",
    "    acc     = (outputs_cpy == labels_cpy).sum()\n",
    "    return acc/outputs_cpy.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, root, image_names, Dict, classes_unique, transform = None):\n",
    "        self.root           = root\n",
    "        self.names          = image_names\n",
    "        self.classes_unique = classes_unique\n",
    "        self.Dict           = Dict\n",
    "        self.transform      = transform        \n",
    "            \n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.root +self.names[idx])\n",
    "        if len(image.shape)!=3:\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "        label_name = Dict[self.names[idx]]\n",
    "        label      = self.classes_unique.index(label_name)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = os.listdir('./tiny-imagenet-200//val/images/')\n",
    "valid_names = random.sample(image_names, 3000)\n",
    "train_names = [i for i in image_names if i not in valid_names]\n",
    "\n",
    "labels_file = open('./tiny-imagenet-200/val/val_annotations.txt', 'r')\n",
    "text = labels_file.read()\n",
    "labels_file.close()\n",
    "text = text.split()\n",
    "i = 1\n",
    "n = len(text)\n",
    "classes = []\n",
    "Dict = {}\n",
    "while(1):\n",
    "    classes.append(text[i])\n",
    "    Dict[text[i-1]] = text[i]\n",
    "    i += 6\n",
    "    if(i > n):\n",
    "        break\n",
    "        \n",
    "classes_unique = list(set(classes))\n",
    "classes_unique.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "trainDataset = ClassifierDataset('./tiny-imagenet-200/val/images/', train_names, Dict, classes_unique, transform = transform)\n",
    "validDataset = ClassifierDataset('./tiny-imagenet-200/val/images/', valid_names, Dict, classes_unique, transform = transform)\n",
    "trainLoader  = DataLoader(trainDataset, batch_size = 16, shuffle = True)\n",
    "validLoader  = DataLoader(validDataset, batch_size = 16, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*13 * 13, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 200)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.size())\n",
    "        x = x.view(-1, 16 * 13 * 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1a = nn.Conv2d(3,  64, 3, padding = 1)\n",
    "        self.conv1b = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        self.pool1  = nn.MaxPool2d(2, 2, return_indices = True)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(64,  128, 3, padding = 1)\n",
    "        self.conv2b = nn.Conv2d(128, 128, 3, padding = 1)\n",
    "        self.pool2  = nn.MaxPool2d(2, 2, return_indices = True)\n",
    "        \n",
    "        self.conv3a = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "        self.conv3b = nn.Conv2d(256, 256, 3, padding = 1)\n",
    "        self.conv3c = nn.Conv2d(256, 256, 3, padding = 1)\n",
    "        self.conv3d = nn.Conv2d(256, 256, 3, padding = 1)\n",
    "        self.pool3  = nn.MaxPool2d(2, 2, return_indices = True)\n",
    "        \n",
    "        self.conv4a = nn.Conv2d(256, 512, 3, padding = 1)\n",
    "        self.conv4b = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "        self.conv4c = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "        self.conv4d = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "        self.pool4  = nn.MaxPool2d(2, 2, return_indices = True)\n",
    "        self.fc1  = nn.Linear(512*4*4, 1024)\n",
    "        self.fc2  = nn.Linear(1024, n_classes)\n",
    "                                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1a = F.relu(self.conv1a(x), inplace = True)\n",
    "        conv1b = F.relu(self.conv1b(conv1a), inplace = True)\n",
    "        pool1, idxs1 = self.pool1(conv1b)\n",
    "        \n",
    "        conv2a = F.relu(self.conv2a(pool1), inplace = True)\n",
    "        conv2b = F.relu(self.conv2b(conv2a), inplace = True)\n",
    "        pool2, idxs2 = self.pool2(conv2b)\n",
    "        \n",
    "        conv3a = F.relu(self.conv3a(pool2), inplace = True)\n",
    "        conv3b = F.relu(self.conv3b(conv3a), inplace = True)\n",
    "        conv3c = F.relu(self.conv3c(conv3b), inplace = True)\n",
    "        conv3d = F.relu(self.conv3d(conv3c), inplace = True)\n",
    "        pool3, idxs3 = self.pool3(conv3d)\n",
    "        \n",
    "        conv4a = F.relu(self.conv4a(pool3), inplace = True)\n",
    "        conv4b = F.relu(self.conv4b(conv4a), inplace = True)\n",
    "        conv4c = F.relu(self.conv4c(conv4b), inplace = True)\n",
    "        conv4d = F.relu(self.conv4d(conv4c), inplace = True)\n",
    "        pool4, idxs4 = self.pool4(conv4d)\n",
    "        flatten = pool4.view(-1, 512*4*4)\n",
    "        fc1  = F.relu(self.fc1(flatten), inplace = True)\n",
    "        fc2 = self.fc2(fc1)\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1a = nn.Conv2d(3, 64, 3,  padding = 1)\n",
    "        self.conv1b = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        self.pool1  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(64, 128, 3,  padding = 1)\n",
    "        self.conv2b = nn.Conv2d(128, 128, 3, padding = 1)\n",
    "        self.pool2  = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128*16*16, 1024)\n",
    "        self.fc2 = nn.Linear(1024, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1a = F.relu(self.conv1a(x), inplace = True)\n",
    "        conv1b = F.relu(self.conv1b(conv1a), inplace = True)\n",
    "        pool1  = self.pool1(conv1b)\n",
    "        \n",
    "        conv2a = F.relu(self.conv2a(pool1), inplace = True)\n",
    "        conv2b = F.relu(self.conv2b(conv2a), inplace = True)\n",
    "        pool2  = self.pool2(conv2b)\n",
    "        \n",
    "        flatten = pool2.view(-1, 128*16*16)\n",
    "        fc1 = F.relu(self.fc1(flatten), inplace = True)\n",
    "        fc2 = self.fc2(fc1)\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        ## Define layers of a CNN\n",
    "        # convolutional layer (sees 224x224x3 image tensor)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1 )        \n",
    "        # convolutional layer (sees 112x112x16 image tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        # convolutional layer (sees 56x56x32 image tensor)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        # convolutional layer (sees 28x28x64 image tensor)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, padding = 1)        \n",
    "        # convolutional layer (sees 14x14x128 image tensor)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding = 1 )\n",
    "        \n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # dropout layer (p=0.2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.conv_bn1 = nn.BatchNorm2d(224,3)\n",
    "        self.conv_bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv_bn3 = nn.BatchNorm2d(32)\n",
    "        self.conv_bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv_bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv_bn6 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # linear layer (256 * 7 * 7 -> 512)\n",
    "        self.fc1 = nn.Linear(256*2*2, 512)\n",
    "        # linear layer (256 * 7 * 7 -> n_classes (133))\n",
    "        self.fc2 = nn.Linear(512, 200)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.conv_bn2(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.conv_bn3(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.conv_bn4(x)\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.conv_bn5(x)\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.conv_bn6(x)\n",
    "        \n",
    "        # flatten image input\n",
    "        x = x.view(-1, 256 * 2 * 2)  \n",
    "        #print(x.size())\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add second hidden layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "netC = Classifier(200)\n",
    "use_gpu = True\n",
    "if use_gpu: \n",
    "    netC.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'mean')\n",
    "optimizer = optim.Adam(netC.parameters(), lr = 1e-2)\n",
    "#optimizer = optim.SGD(netC.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainLoader:\n",
    "    images, labels  = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1/100| Train Loss: 7.86763| Valid Loss: 5.31500| Train Acc: 24.00000| Valid Acc: 9.00000]\n",
      "[Epoch: 2/100| Train Loss: 5.30876| Valid Loss: 5.32050| Train Acc: 24.00000| Valid Acc: 10.00000]\n",
      "[Epoch: 3/100| Train Loss: 5.30834| Valid Loss: 5.32377| Train Acc: 37.00000| Valid Acc: 10.00000]\n",
      "[Epoch: 4/100| Train Loss: 5.30832| Valid Loss: 5.32454| Train Acc: 37.00000| Valid Acc: 8.00000]\n",
      "[Epoch: 5/100| Train Loss: 5.30853| Valid Loss: 5.32417| Train Acc: 29.00000| Valid Acc: 7.00000]\n",
      "[Epoch: 6/100| Train Loss: 5.30869| Valid Loss: 5.32425| Train Acc: 35.00000| Valid Acc: 10.00000]\n",
      "[Epoch: 7/100| Train Loss: 5.30830| Valid Loss: 5.32417| Train Acc: 32.00000| Valid Acc: 7.00000]\n",
      "[Epoch: 8/100| Train Loss: 5.30881| Valid Loss: 5.32358| Train Acc: 24.00000| Valid Acc: 7.00000]\n",
      "[Epoch: 9/100| Train Loss: 5.30859| Valid Loss: 5.32463| Train Acc: 23.00000| Valid Acc: 7.00000]\n",
      "[Epoch: 10/100| Train Loss: 5.30829| Valid Loss: 5.32415| Train Acc: 31.00000| Valid Acc: 11.00000]\n",
      "[Epoch: 11/100| Train Loss: 5.30844| Valid Loss: 5.32438| Train Acc: 34.00000| Valid Acc: 8.00000]\n",
      "[Epoch: 12/100| Train Loss: 5.30868| Valid Loss: 5.32393| Train Acc: 36.00000| Valid Acc: 8.00000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b8bb0e759b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mepochTrainLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mepochTrainAcc\u001b[0m  \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "trainLoss = []\n",
    "validLoss = []\n",
    "trainAcc  = []\n",
    "validAcc  = []\n",
    "for epoch in range(epochs):\n",
    "    epochTrainLoss = 0\n",
    "    epochValidLoss = 0\n",
    "    epochTrainAcc  = 0\n",
    "    epochValidAcc  = 0\n",
    "\n",
    "    netC.train(True)\n",
    "    for data in trainLoader:\n",
    "        images, labels = data\n",
    "        if use_gpu:\n",
    "            images = images.cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        outputs = netC(images)\n",
    "        #print(outputs)\n",
    "        #print(outputs[0].sum())\n",
    "        optimizer.zero_grad()\n",
    "        loss    = criterion(outputs, labels)\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epochTrainLoss += loss.item()\n",
    "        epochTrainAcc  += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    netC.train(False)\n",
    "    for data in validLoader:\n",
    "        images, labels = data\n",
    "        if use_gpu:\n",
    "            images = images.cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        outputs = netC(images)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        predicted = torch.max(outputs, 1)[1]\n",
    "        epochValidLoss += loss.item()\n",
    "        epochValidAcc  += (predicted == labels).sum().item()\n",
    "    epochTrainAcc  = epochTrainAcc#/len(trainLoader)\n",
    "    epochValidAcc  = epochValidAcc#/len(validLoader)\n",
    "    epochTrainLoss = epochTrainLoss/len(trainLoader)\n",
    "    epochValidLoss = epochValidLoss/len(validLoader)\n",
    "    trainLoss.append(epochTrainLoss)\n",
    "    validLoss.append(epochValidLoss)\n",
    "    trainAcc.append(epochTrainAcc  )\n",
    "    validAcc.append(epochTrainAcc  )\n",
    "\n",
    "    if epoch!=0:\n",
    "        if(epochValidAcc > bestValidAcc):\n",
    "            bestValidAcc = epochValidAcc\n",
    "            torch.save(netC.state_dict(), 'classifier.pth')\n",
    "    else: \n",
    "        bestValidAcc = epochValidAcc     \n",
    "    print('[Epoch: {:.0f}/{:.0f}| Train Loss: {:.5f}| Valid Loss: {:.5f}| Train Acc: {:.5f}| Valid Acc: {:.5f}]'.format(epoch+1, epochs, epochTrainLoss, epochValidLoss, epochTrainAcc, epochValidAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 1, 1], [1, 2, 3]])\n",
    "a = nn.Softmax(1)\n",
    "a(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[7].cpu().detach().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
